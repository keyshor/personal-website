<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kishor Jothimurugan</title>
    <link>https://seas.upenn.edu/~kishor/</link>
    <description>Recent content on Kishor Jothimurugan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://seas.upenn.edu/~kishor/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Other_projects</title>
      <link>https://seas.upenn.edu/~kishor/other_projects/</link>
      <pubDate>Fri, 11 Oct 2019 13:14:31 -0400</pubDate>
      
      <guid>https://seas.upenn.edu/~kishor/other_projects/</guid>
      <description>Internships  Research Internship at Nokia Bell Labs (Summer 2020). I worked on applications of deep reinforcement learning and imitation learning to real time decision making problems such as logistics optimization. I also spent some time on applying RL to collision avoidance in drones.
 SDE Internship at Amazon Web Services (Summer 2019). I interned with the Automated Reasoning Group at AWS. I worked on automatically discovering sinks of sensitive data in Java code.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://seas.upenn.edu/~kishor/projects/</link>
      <pubDate>Fri, 11 Oct 2019 10:40:07 -0400</pubDate>
      
      <guid>https://seas.upenn.edu/~kishor/projects/</guid>
      <description>Projects  Formal Methods for Reinforcement Learning. Reinforcement learning is a promising approach for learning control policies for robot tasks. This project focusses on applying techniques from logic and formal methods to enhance reinforcement learning. For example, how to compile formal logical specifications to reward functions so that one can use existing RL algorithms to learn policies for such specifications? How to use state abstractions for hierarchical reinforcement learning? How to verify/test learned policies for safety properties?</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://seas.upenn.edu/~kishor/publications/</link>
      <pubDate>Fri, 11 Oct 2019 10:40:00 -0400</pubDate>
      
      <guid>https://seas.upenn.edu/~kishor/publications/</guid>
      <description>Publications  A composable specification language for reinforcement learning tasks, Kishor Jothimurugan, Rajeev Alur, Osbert Bastani. Neural Information Processing Systems (NeurIPS), 2019.
[paper][slides][code]
 Space-efficient query evaluation over probabilistic event streams, Rajeev Alur, Yu Chen, Kishor Jothimurugan, Sanjeev Khanna. Logic in Computer Science (LICS), 2020.
[paper][slides]
  Drafts and Reports  Abstract value iteration for hierarchical deep reinforcement learning, Kishor Jothimurugan, Osbert Bastani, Rajeev Alur. In submission.
 Techniques for verifying robustness of neural networks, Kishor Jothimurugan.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://seas.upenn.edu/~kishor/introduction/</link>
      <pubDate>Fri, 11 Oct 2019 10:39:41 -0400</pubDate>
      
      <guid>https://seas.upenn.edu/~kishor/introduction/</guid>
      <description>I am a third-year PhD student in computer science at the University of Pennsylvania. I am being advised by Rajeev Alur. I received my B.Sc. (Honors) in Mathematics and Computer Science from the Chennai Mathematical Institute.
My (broad) areas of interest include formal methods, verification, and machine learning. In particular, I am interested in applying formal methods to improve applicability and reliability of deep reinforcement learning, verifying systems with neural network components, and using machine learning to improve scalability of program analysis and verification.</description>
    </item>
    
  </channel>
</rss>